# ğŸ“„ DocWise RAG OpenAI

> Um pipeline simples e funcional de Retrieval-Augmented Generation (RAG) para PDFs usando OpenAI, LangChain e FAISS, escrito 100% em Python. Ideal para aprendizado, POCs ou projetos internos.



## ğŸš€ VisÃ£o Geral

**DocWise RAG OpenAI** permite carregar documentos PDF, processÃ¡-los com chunking, gerar embeddings com a API da OpenAI e armazenar os vetores localmente usando FAISS. A partir disso, vocÃª pode fazer perguntas em linguagem natural e obter respostas baseadas no conteÃºdo dos documentos.



## ğŸ“ Estrutura do Projeto

```

docwise-rag-openai/
â”œâ”€â”€ .env                      # VariÃ¡veis de ambiente (nÃ£o versionar)
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ main.py                   # Entrada principal da aplicaÃ§Ã£o (chat de perguntas)
â”œâ”€â”€ ingest.py                 # Script de ingestÃ£o de PDFs e criaÃ§Ã£o de Ã­ndice FAISS
â”œâ”€â”€ config.py                 # Carregamento de configuraÃ§Ãµes do .env
â”œâ”€â”€ rag/                      # MÃ³dulos principais do pipeline
â”‚   â”œâ”€â”€ **init**.py
â”‚   â”œâ”€â”€ loader.py             # Leitura dos PDFs
â”‚   â”œâ”€â”€ splitter.py           # Split dos textos em chunks
â”‚   â”œâ”€â”€ embedder.py           # CriaÃ§Ã£o dos embeddings
â”‚   â”œâ”€â”€ vectorstore.py        # Armazenamento/recarregamento FAISS
â”‚   â””â”€â”€ qa.py                 # Pipeline de perguntas e respostas
â”œâ”€â”€ data/                     # Pasta para armazenar os PDFs
â”‚   â””â”€â”€ seu-arquivo.pdf

````



## ğŸ› ï¸ PrÃ©-Requisitos

- Python 3.10+
- API Key vÃ¡lida da [OpenAI](https://platform.openai.com/account/api-keys)
- Crie um ambiente virtual:

```bash
python -m venv .venv
.\.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/macOS
````



## ğŸ“¦ InstalaÃ§Ã£o

Instale as dependÃªncias com:

```bash
pip install -r requirements.txt
```



## ğŸ” ConfiguraÃ§Ã£o `.env`

Crie um arquivo `.env` na raiz do projeto com o seguinte conteÃºdo:

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_LLM_MODEL=gpt-4o  # ou gpt-3.5-turbo, gpt-4, etc.
DATA_DIR=data
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

> âš ï¸ Nunca compartilhe sua API Key pÃºblica ou versionada!



## ğŸ§  Pipeline de IngestÃ£o

Este processo carrega os PDFs da pasta `data/`, divide o conteÃºdo em chunks e gera os embeddings que serÃ£o salvos no Ã­ndice local (`faiss_index/`):

```bash
python ingest.py
```



## ğŸ’¬ Interagindo com o Assistente

ApÃ³s a ingestÃ£o, execute:

```bash
python main.py
```

VocÃª verÃ¡ o prompt interativo:

```
ğŸ” FaÃ§a uma pergunta sobre os documentos PDF (ou digite 'sair'):

â“ Pergunta:
```

Digite qualquer pergunta em linguagem natural com base nos documentos PDF carregados. Exemplo:

```
â“ Pergunta: Qual o prazo para entrega da proposta?
```



## ğŸ§ª Exemplos de Perguntas

* "Quais sÃ£o os critÃ©rios de avaliaÃ§Ã£o da RFP?"
* "A proposta deve ser enviada por e-mail ou sistema?"
* "Existe alguma exigÃªncia de certificaÃ§Ã£o tÃ©cnica?"
* "Qual o valor estimado do contrato?"



## ğŸ§° Tecnologias Utilizadas

* [LangChain](https://python.langchain.com/)
* [OpenAI API](https://platform.openai.com/)
* [FAISS](https://github.com/facebookresearch/faiss)
* [PyPDF2](https://github.com/py-pdf/PyPDF2)
* [dotenv](https://pypi.org/project/python-dotenv/)



## ğŸ§¼ Limpeza e ReindexaÃ§Ã£o

Se desejar reprocessar os PDFs (por exemplo, apÃ³s atualizar os arquivos), exclua o diretÃ³rio `faiss_index/`:

```bash
rm -rf faiss_index/
```

E execute novamente:

```bash
python ingest.py
```



## âš ï¸ Avisos

* Este projeto usa **deserializaÃ§Ã£o com Pickle** para FAISS, o que **deve ser evitado com fontes nÃ£o confiÃ¡veis**. Use `allow_dangerous_deserialization=True` **somente se vocÃª confia na origem do Ã­ndice FAISS.**
* Ã‰ um projeto educacional/demonstrativo, **nÃ£o recomendado para produÃ§Ã£o sem adaptaÃ§Ãµes.**



## ğŸ§­ PrÃ³ximos Passos (SugestÃµes)

* âœ… Suporte a mÃºltiplos arquivos PDF
* ğŸ“Š Interface web com Streamlit ou Gradio
* ğŸŒ Suporte multilÃ­ngue
* ğŸ” Controle de acesso e histÃ³rico de perguntas
* â˜ï¸ Armazenamento vetorial remoto (ex: Weaviate, Pinecone, Azure AI Search)



## ğŸ“– LicenÃ§a

MIT License â€” sinta-se Ã  vontade para clonar, estudar e adaptar!



## âœï¸ Autor

Esteves Marques â€” [iaplaybook.tech](https://iaplaybook.tech)
Siga a jornada no LinkedIn: [@estevesmarques](https://linkedin.com/in/estevesmarques)
